\section{Abstract}\label{Chapter_1_Motivation}

\noindent The accurate and efficient classification of skin lesions from dermatoscopic images is a critical task for the early diagnosis of melanoma and other skin cancers. While deep learning models have demonstrated dermatologist-level performance, existing architectures face a trade-off between accuracy and computational efficiency. Standard Convolutional Neural Networks (CNNs) excel at extracting local features but may miss global context, whereas Vision Transformers (ViTs) model global relationships but can overlook fine-grained textures crucial for diagnosis. To address these limitations, we propose a novel three-phase training pipeline. First, we introduce the Context-Aware Hierarchical Vision Transformer (CA-HVT), a high-performance teacher model that synergizes a hierarchical CNN stem with a global context Transformer body via a novel Cross-Scale Fusion (CSF) block. This architecture effectively integrates local details with global structural information. Second, to enable practical deployment, we propose Attention-Guided Relational Knowledge Distillation (ARK-KD), an advanced framework to transfer the comprehensive knowledge of the large CA-HVT teacher to a lightweight and efficient TinyViT student model. ARK-KD goes beyond traditional distillation by transferring the teacher's feature space geometry and spatial attention patterns. Our comprehensive evaluation on the HAM10000 dataset demonstrates that our distilled student model achieves state-of-the-art accuracy while being significantly more computationally efficient, making it suitable for real-world clinical applications.

\newpage
\section{Introduction}\label{Chapter_1_Motivation}

\noindent The accurate and efficient classification of skin lesions from dermatoscopic images is a critical task for the early diagnosis of melanoma and other skin cancers\textbf{rewrite the sentence in your words, looks too much chatgpt}. Across specialties from radiology to pathology, machine learning algorithms are being developed to analyze complex medical data, identify patterns imperceptible to the human eye, and provide quantitative, reproducible insights to aid clinical decision-making. In the field of dermatology, the diagnosis of skin cancer from visual inspection of dermatoscopic images represents a particularly significant challenge, characterized by subtle visual cues, a wide spectrum of presentations, and high inter-observer variability among clinicians. This thesis delves into this critical domain, addressing the pressing need for diagnostic tools that are not only accurate but also practical for real-world application. We propose a novel deep learning pipeline designed to overcome the architectural and practical limitations of current-generation models. We intend to propose a new hybrid architecture that mimics the multi-scale, hierarchical reasoning of a human expert and pair it with an advanced knowledge transfer mechanism to produce a final model that is both highly accurate and computationally efficient for practical deployment in clinical settings.


 % Background
\section{Background}\label{Chapter_1_Motivation}

% \noindent Skin cancer remains one of the most prevalent forms of cancer globally, with melanoma being its most lethal variant due to its high propensity for metastasis \cite{siegel2020cancer}. Early and accurate diagnosis is the most critical factor in improving patient prognosis and survival rates. Dermoscopy is a non-invasive imaging technique that utilizes magnification, liquid immersion, and specialized, often polarized, illumination to visualize subsurface skin structures invisible to the naked eye. It has become the gold standard in clinical practice for the evaluation of pigmented and non-pigmented skin lesions \cite{zalaudek2006nodular}, helping clinicians better differentiate between benign nevi and malignant melanoma.
% The clinical assessment of these images often relies on structured methodologies, such as the ABCDE rule (Asymmetry, Border irregularity, Color variegation, Diameter greater than 6mm, Evolving) \textbf{discuss the rule in detail in next few sentences}. While effective, the interpretation of these features is a complex perceptual skill that requires extensive training and experience. Significant visual overlap between malignant and benign conditions, such as nodular melanoma and seborrheic keratosis, or between melanoma and dysplastic nevi, can lead to diagnostic ambiguity even for seasoned dermatologists, resulting in unnecessary biopsies of benign lesions or, more critically, missed diagnoses of malignant ones\textbf{too long sentence divide into seperate sentences }.

Skin cancer remains one of the most prevalent forms of cancer globally, with melanoma being its most lethal variant due to its high propensity for metastasis \cite{siegel2020cancer}. Early and accurate diagnosis is the most critical factor in improving patient prognosis and survival rates. Dermoscopy is a non-invasive imaging technique that utilizes magnification, liquid immersion, and specialized, often polarized, illumination to visualize subsurface skin structures invisible to the naked eye. It has become the gold standard in clinical practice for the evaluation of pigmented and non-pigmented skin lesions \cite{zalaudek2006nodular}, helping clinicians better differentiate between benign nevi and malignant melanoma.

The clinical assessment of these images often relies on structured methodologies, such as the ABCDE rule (Asymmetry, Border irregularity, Color variegation, Diameter greater than 6mm, Evolving). This mnemonic guides the evaluation of key morphological features. Asymmetry refers to the lesion's shape, where one half does not match the other. The Border of a suspicious lesion is often uneven, scalloped, or poorly defined. Color variegation is another warning sign, indicated by the presence of multiple shades of brown, black, red, or blue within the same lesion. The Diameter of melanomas is typically larger than 6mm, though they can be diagnosed when smaller. Finally, Evolving signifies any change in a mole's size, shape, color, or symptoms over time.

While this rule is effective, interpreting these features is a complex perceptual skill that requires extensive training and experience. A primary challenge in dermatoscopic diagnosis is the significant visual overlap between malignant and benign conditions. For instance, nodular melanoma can mimic seborrheic keratosis, and early melanoma can appear similar to dysplastic nevi. This ambiguity often leads to diagnostic uncertainty, even for seasoned dermatologists. Consequently, this results in two adverse outcomes: a high rate of unnecessary biopsies for benign lesions and the critical risk of missed melanoma diagnoses.

\section{Motivation}\label{Chapter_1_Motivation}

\noindent 
% To augment the diagnostic process, reduce inter-observer variability, and provide a quantitative baseline for analysis, Computer-Aided Diagnosis (CAD) systems have become an area of intense research \textbf{feels like sudden jump, add a sentence before starting this}. The advent of deep learning has revolutionized this field. Seminal work by Esteva et al.  demonstrated that deep learning models, specifically Convolutional Neural Networks (CNNs), could achieve a level of classification accuracy for skin lesions on par with board-certified dermatologists. These models, such as ResNet \cite{he2016resnet} and its contemporaries, are powerful due to their ability to learn hierarchical feature representations directly from pixel data, capturing diagnostically relevant local patterns like textures, colors, and fine structures \textbf{describe the different approaches a bit in detail, maybe a couple of sentences, avoid writing generic sentences}.
% Despite their success, these models have inherent limitations. CNNs, with their localized receptive fields, often struggle to model the long-range spatial dependencies that define global lesion properties like overall shape, symmetry, and border irregularity—key indicators in clinical diagnostic rubrics\textbf{break into two sentences}. The recent emergence of the Vision Transformer (ViT)  has provided a powerful new paradigm for image recognition. By treating an image as a sequence of patches and applying a self-attention mechanism, ViTs \textbf{any specific ViT available for this task} excel at modeling global context. However, they typically require massive datasets for pre-training and their uniform patching strategy can disrupt fine-grained textures that are diagnostically critical. Furthermore, both high-accuracy CNNs and ViTs are often computationally intensive, creating a significant barrier to their deployment in resource-constrained clinical settings or on mobile health platforms \textbf{very good}. This necessitates a solution that is not only highly accurate but also computationally efficient. This paper is motivated by the need to bridge these gaps by developing an architecture that explicitly models the multi-scale reasoning process of a dermatologist while creating a final model that is efficient enough for practical clinical deployment.


To address these inherent challenges in manual interpretation, Computer-Aided Diagnosis (CAD) systems have become an area of intense research. The advent of deep learning has revolutionized this field. Seminal work by Esteva et al. \cite{esteva2017dermatologist} demonstrated that deep learning models, specifically Convolutional Neural Networks (CNNs), could achieve a level of classification accuracy for skin lesions on par with board-certified dermatologists. These models employ different strategies to learn robust features. For instance, architectures like ResNet utilize residual connections to enable the training of exceptionally deep networks capable of learning complex feature hierarchies [4], while others, like the Inception family, use multi-scale convolutional kernels in parallel to capture patterns of varying sizes within the same lesion.

Despite their success, these models have inherent limitations. CNNs, with their localized receptive fields, often struggle to model the long-range spatial dependencies required to assess the overall structure of a lesion. This makes it difficult for them to holistically evaluate global properties like overall shape, symmetry, and border irregularity—key indicators in clinical diagnostic rubrics. The recent emergence of the Vision Transformer (ViT) \cite{dosovitskiy2021vit} has provided a powerful new paradigm for image recognition. By treating an image as a sequence of patches and applying a self-attention mechanism, ViTs and their hierarchical variants like the Swin Transformer excel at modeling global context. However, they typically require massive datasets for pre-training and their uniform patching strategy can disrupt fine-grained textures that are diagnostically critical. Furthermore, both high-accuracy CNNs and ViTs are often computationally intensive, creating a significant barrier to their deployment in resource-constrained clinical settings or on mobile health platforms. This necessitates a solution that is not only highly accurate but also computationally efficient. This paper is motivated by the need to bridge these gaps by developing an architecture that explicitly models the multi-scale reasoning process of a dermatologist while creating a final model that is efficient enough for practical clinical deployment.